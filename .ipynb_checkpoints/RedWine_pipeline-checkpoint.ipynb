{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Red Wine Quality \n",
    "\n",
    "This project is using both automated ML and bespoke ML to create a model that predicts the quality of wine based on a subset of features. This data was taken from a Kaggle project (https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009). \n",
    "\n",
    "To perform the Auto ML, this notebook interacts with the Azure ML SDK to set up an Auto ML experiemtn. This then progresses to creating an automated pipeline to run training experiments and registering the machine learning models.\n",
    "\n",
    "## Steps taken in this notebook\n",
    " -  Connecting to an Azure workspace\n",
    " -  Preparing the data\n",
    " -  Creating a Compute Target\n",
    " -  Running an Auto ML experiment on Azure\n",
    " -  Analysing the Auto ML output \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Connecting to an Azure workspace\n",
    "\n",
    "An Azure ML Workspace was set up within portal.azure.com and a compute instance has been set up. The following code will connect to the Azure ML Workspace created in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code CGNZJQ73G to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "Ready to use the redwine workspace on Azure ML 1.7.0\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use the {} workspace on Azure ML {}'.format(ws.name, azureml.core.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Preparing the data\n",
    "\n",
    "The data used in this experiment was downloaded from https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009. \n",
    "The steps below, import the data if it is not currently present in the workspace data store creating a tabular dataset and registering this within Azure.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./RedWine/Red Wine Quality.csv\n",
      "Uploaded ./RedWine/Red Wine Quality.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Dataset registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'red wine dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./RedWine/Red Wine Quality.csv'], # Upload the red wine csv file in /RedWine\n",
    "                        target_path='red-wine-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore.\n",
    "    full_rw_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'red-wine-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        full_rw_data_set = full_rw_data_set.register(workspace=ws, \n",
    "                                name='red wine dataset',\n",
    "                                description='red wine quality data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Create a Compute Target\n",
    "Creating a Compute Cluster in Azure to be used for subsequent ML tasks. \n",
    "\n",
    "__*Note*__ - If local compute is going to be used, this step is not required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"red-wine-1\" \n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS2_V2', max_nodes=2)\n",
    "    training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "training_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Using Auto ML to guide the ML algorithm to use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training and validation subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready!\n"
     ]
    }
   ],
   "source": [
    "redwine_ds = ws.datasets.get(\"red wine dataset\")\n",
    "train_ds, test_ds = redwine_ds.random_split(percentage=0.7, seed=123)\n",
    "print(\"Data ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring an AutoML experiment to run on a compute cluster.  \n",
    "- Run configuration that includes the required packages for the experiment environment\n",
    "- Set the configuration settings to specify how many combinations to try (if the number of iterations are not specified, the default is 1000).\n",
    "- Set the metric to use when evaluating models. The task here is 'regression' so the options to chose from are:\n",
    " - Spearman Correlation\n",
    " - Normalized Root Mean Squared Error\n",
    " - R-squared\n",
    " - Normalised Mean Absolute Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready for Auto ML run.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(name='Automated ML Experiment',\n",
    "                             task='regression',\n",
    "                             compute_target=training_cluster,\n",
    "                             enable_local_managed=True,\n",
    "                             training_data = train_ds,\n",
    "                             validation_data = test_ds,\n",
    "                             label_column_name='quality',\n",
    "                             iterations=500,\n",
    "                             primary_metric = 'r2_score',\n",
    "                             max_concurrent_iterations=10,\n",
    "                             featurization='auto',\n",
    "                             model_explainability=True\n",
    "                             )\n",
    "\n",
    "print(\"Ready for Auto ML run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Auto ML experiment using the config file created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting Auto ML experiment...\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "print('Submitting Auto ML experiment...')\n",
    "automl_experiment = Experiment(ws, 'redwine_automl')\n",
    "automl_run = automl_experiment.submit(automl_config)\n",
    "RunDetails(automl_run).show()\n",
    "automl_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the best model from the AutoML experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'automl_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-48226d8e9983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidgets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunDetails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#print(fitted_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'automl_run' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "best_run, fitted_model = automl_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'automl_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-677c19aed65e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmetricslist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'automl_run' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "children = list(automl_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata.to_csv('RedWine/rundata.csv')\n",
    "rundata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing the results of the AutoML and picking out those with the best metrics to allow comparison of the best models more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>explained_variance</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>mean_absolute_percentage_error</th>\n",
       "      <th>median_absolute_error</th>\n",
       "      <th>normalized_mean_absolute_error</th>\n",
       "      <th>normalized_median_absolute_error</th>\n",
       "      <th>normalized_root_mean_squared_error</th>\n",
       "      <th>normalized_root_mean_squared_log_error</th>\n",
       "      <th>r2_score</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>root_mean_squared_log_error</th>\n",
       "      <th>spearman_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.49232</td>\n",
       "      <td>0.40188</td>\n",
       "      <td>7.42868</td>\n",
       "      <td>0.301803</td>\n",
       "      <td>0.0803761</td>\n",
       "      <td>0.0603607</td>\n",
       "      <td>0.111159</td>\n",
       "      <td>0.106438</td>\n",
       "      <td>0.490989</td>\n",
       "      <td>0.555793</td>\n",
       "      <td>0.0863138</td>\n",
       "      <td>0.732499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.441908</td>\n",
       "      <td>0.396111</td>\n",
       "      <td>7.40795</td>\n",
       "      <td>0.284356</td>\n",
       "      <td>0.0792223</td>\n",
       "      <td>0.0568713</td>\n",
       "      <td>0.116871</td>\n",
       "      <td>0.112212</td>\n",
       "      <td>0.437325</td>\n",
       "      <td>0.584357</td>\n",
       "      <td>0.090996</td>\n",
       "      <td>0.694177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.490253</td>\n",
       "      <td>0.398293</td>\n",
       "      <td>7.35103</td>\n",
       "      <td>0.292824</td>\n",
       "      <td>0.0796586</td>\n",
       "      <td>0.0585648</td>\n",
       "      <td>0.111459</td>\n",
       "      <td>0.106531</td>\n",
       "      <td>0.48823</td>\n",
       "      <td>0.557297</td>\n",
       "      <td>0.0863895</td>\n",
       "      <td>0.728791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.366982</td>\n",
       "      <td>0.40974</td>\n",
       "      <td>7.61672</td>\n",
       "      <td>0.248313</td>\n",
       "      <td>0.0819479</td>\n",
       "      <td>0.0496626</td>\n",
       "      <td>0.124368</td>\n",
       "      <td>0.118526</td>\n",
       "      <td>0.362821</td>\n",
       "      <td>0.621842</td>\n",
       "      <td>0.0961164</td>\n",
       "      <td>0.639898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0 explained_variance mean_absolute_error  \\\n",
       "498                   0.49232             0.40188   \n",
       "356                  0.441908            0.396111   \n",
       "499                  0.490253            0.398293   \n",
       "312                  0.366982             0.40974   \n",
       "\n",
       "Unnamed: 0 mean_absolute_percentage_error median_absolute_error  \\\n",
       "498                               7.42868              0.301803   \n",
       "356                               7.40795              0.284356   \n",
       "499                               7.35103              0.292824   \n",
       "312                               7.61672              0.248313   \n",
       "\n",
       "Unnamed: 0 normalized_mean_absolute_error normalized_median_absolute_error  \\\n",
       "498                             0.0803761                        0.0603607   \n",
       "356                             0.0792223                        0.0568713   \n",
       "499                             0.0796586                        0.0585648   \n",
       "312                             0.0819479                        0.0496626   \n",
       "\n",
       "Unnamed: 0 normalized_root_mean_squared_error  \\\n",
       "498                                  0.111159   \n",
       "356                                  0.116871   \n",
       "499                                  0.111459   \n",
       "312                                  0.124368   \n",
       "\n",
       "Unnamed: 0 normalized_root_mean_squared_log_error  r2_score  \\\n",
       "498                                      0.106438  0.490989   \n",
       "356                                      0.112212  0.437325   \n",
       "499                                      0.106531   0.48823   \n",
       "312                                      0.118526  0.362821   \n",
       "\n",
       "Unnamed: 0 root_mean_squared_error root_mean_squared_log_error  \\\n",
       "498                       0.555793                   0.0863138   \n",
       "356                       0.584357                    0.090996   \n",
       "499                       0.557297                   0.0863895   \n",
       "312                       0.621842                   0.0961164   \n",
       "\n",
       "Unnamed: 0 spearman_correlation  \n",
       "498                    0.732499  \n",
       "356                    0.694177  \n",
       "499                    0.728791  \n",
       "312                    0.639898  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "rundata = pd.read_csv(\"rundata.csv\")\n",
    "toprundata = rundata.transpose()\n",
    "\n",
    "\n",
    "new_headers = toprundata.iloc[0]\n",
    "toprundata = toprundata[1:] \n",
    "toprundata.columns = new_headers\n",
    "\n",
    "\n",
    "df_toprundata =  pd.DataFrame(columns=new_headers)\n",
    "for x in new_headers:\n",
    "    if (x == 'explained_variance') | (x == 'r2_score') | (x == 'spearman_correlation'):\n",
    "        df_toprundata = df_toprundata.append(toprundata[toprundata[x] == toprundata[x].max()])\n",
    "    else:\n",
    "        df_toprundata = df_toprundata.append(toprundata[toprundata[x] == toprundata[x].min()])\n",
    "df_toprundata = df_toprundata.drop_duplicates()\n",
    "df_toprundata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML_5dc0c0a3-d23d-4fb4-b1e6-fe01685fb180\n",
      "AutoML_57cc9c2c-4533-4174-83d0-69b7e8704656\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.run import Run\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(workspace=ws, name='redwine_automl')\n",
    "\n",
    "list_runs = experiment.get_runs()\n",
    "for run in list_runs:\n",
    "    print(run.id)\n",
    "# try to get latest run ID dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objects</th>\n",
       "      <th>pipeline_id</th>\n",
       "      <th>module</th>\n",
       "      <th>class_name</th>\n",
       "      <th>pipeline_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'class_name': 'RobustScaler', 'module': 'skle...</td>\n",
       "      <td>94507fa86843060f774e845b508b5c804f51c2a2</td>\n",
       "      <td>sklearn.pipeline</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>{ RobustScaler, KNeighborsRegressor }</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'class_name': 'KNeighborsRegressor', 'module'...</td>\n",
       "      <td>94507fa86843060f774e845b508b5c804f51c2a2</td>\n",
       "      <td>sklearn.pipeline</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>{ RobustScaler, KNeighborsRegressor }</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             objects  \\\n",
       "0  {'class_name': 'RobustScaler', 'module': 'skle...   \n",
       "1  {'class_name': 'KNeighborsRegressor', 'module'...   \n",
       "\n",
       "                                pipeline_id            module class_name  \\\n",
       "0  94507fa86843060f774e845b508b5c804f51c2a2  sklearn.pipeline   Pipeline   \n",
       "1  94507fa86843060f774e845b508b5c804f51c2a2  sklearn.pipeline   Pipeline   \n",
       "\n",
       "                           pipeline_name  \n",
       "0  { RobustScaler, KNeighborsRegressor }  \n",
       "1  { RobustScaler, KNeighborsRegressor }  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "run_id = 'AutoML_5dc0c0a3-d23d-4fb4-b1e6-fe01685fb180'\n",
    "child_run_id = pd.DataFrame(df_toprundata.index.tolist())\n",
    "df_child_run_id =  run_id + '_' + child_run_id.astype(str)\n",
    "list_child_run_id = df_child_run_id.values.tolist()\n",
    "\n",
    "test = Run(experiment=experiment, run_id='AutoML_5dc0c0a3-d23d-4fb4-b1e6-fe01685fb180_356')\n",
    "# test.get_tags()\n",
    "\n",
    "tags_df = pd.read_json(test.tags['pipeline_script'])\n",
    "tags_df\n",
    "# best_child_run_information =  pd.DataFrame(columns=new_headers)\n",
    "# for x in new_headers:\n",
    "#     if (x == 'explained_variance') | (x == 'r2_score') | (x == 'spearman_correlation'):\n",
    "#         df_toprundata = df_toprundata.append(toprundata[toprundata[x] == toprundata[x].max()])\n",
    "#     else:\n",
    "#         df_toprundata = df_toprundata.append(toprundata[toprundata[x] == toprundata[x].min()])\n",
    "# df_toprundata = df_toprundata.drop_duplicates()\n",
    "# df_toprundata\n",
    "\n",
    "# for model in list_child_run_id:\n",
    "#         tag = run.tags[tag_name]\n",
    "#         print ('\\t',tag_name, ':', tag)\n",
    "#     for prop_name in model.properties:\n",
    "#         prop = model.properties[prop_name]\n",
    "#         print ('\\t',prop_name, ':', prop)\n",
    "#     print('\\n')\n",
    "        \n",
    "#for x in list_child_run_id:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Creating a script for the pipeline steps\n",
    "\n",
    "This pipeline consists of the following steps:\n",
    "\n",
    " - Training the model using an estimator\n",
    " - Registering the trained model\n",
    "\n",
    "Pipelines consist of one or more *steps*, which can be Python scripts, or specialized steps like an Auto ML training estimator or a data transfer step that copies data from one location to another. Each step can run in its own compute context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a folder for the pipeline step files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedWine/Redwine_Pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "experiment_folder = 'RedWine/Redwine_Pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model using an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/train_redwine.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--output_folder', type=str, dest='output_folder', default=\"redwine_model\", help='output folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['diabetes_train'].to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script for the second step of the pipeline will load the model from where it was saved, and then register it in the workspace. It includes a single **model_folder** parameter that contains the path where the model was saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/register_diabetes.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"diabetes_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'diabetes_model',\n",
    "               tags={'Training context':'Pipeline'})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Compute Environment for the Pipeline Steps\n",
    "\n",
    "In this exercise, you'll use the same compute for both steps, but it's important to realize that each step is run independently; so you could specify different compute contexts for each step if appropriate.\n",
    "\n",
    "First, get the compute target you created in a previous lab (if it doesn't exist, it will be created).\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS2_V2', \n",
    "                                                           max_nodes=2)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "pipeline_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute will require a Python environment with the necessary package dependencies installed, so you'll need to create a run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "diabetes_env = Environment(\"diabetes-experiment-env\")\n",
    "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "diabetes_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib', 'pandas'],\n",
    "                                             pip_packages=['azureml-sdk','pyarrow'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "diabetes_env.python.conda_dependencies = diabetes_packages\n",
    "\n",
    "# Register the environment (just in case previous lab wasn't completed)\n",
    "diabetes_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'diabetes-experiment-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run a Pipeline\n",
    "\n",
    "Now you're ready to create and run a pipeline.\n",
    "\n",
    "First you need to define the steps for the pipeline, and any data references that need to passed between them. In this case, the first step must write the model to a folder that can be read from by the second step. Since the steps will be run on remote compute (and in fact, could each be run on different compute), the folder path must be passed as a data reference to a location in a datastore within the workspace. The **PipelineData** object is a special kind of data reference that is used for interim storage locations that can be passed between pipeline steps, so you'll create one and use at as the output for the first step and the input for the second step. Note that you also need to pass it as a script argument so our code can access the datastore location referenced by the data reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                        compute_target = pipeline_cluster,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='train_diabetes.py')\n",
    "\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[diabetes_ds.as_named_input('diabetes_train')],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = pipeline_cluster,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"register_diabetes.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, you're ready build the pipeline from the steps you've defined and run it as an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'diabetes-training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The widget above shows details of the pipeline as it runs. You can also monitor pipeline runs in the **Experiments** page in [Azure Machine Learning studio](https://ml.azure.com).\n",
    "\n",
    "When the pipeline has finished, a new model should be registered with a *Training context* tag indicating it was trained in a pipeline. Run the following code to verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple example, designed to demonstrate the principle. In reality, you could build more sophisticated logic into the pipeline steps - for example, evaluating the model against some test data to calculate a performance metric like AUC or accuracy, comparing the metric to that of any previously registered versions of the model, and only registering the new model if it performs better.\n",
    "\n",
    "You can use the [Azure Machine Learning extension for Azure DevOps](https://marketplace.visualstudio.com/items?itemName=ms-air-aiagility.vss-services-azureml) to combine Azure ML pipelines with Azure DevOps pipelines (yes, it *is* confusing that they have the same name!) and integrate model retraining into a *continuous integration/continuous deployment (CI/CD)* process. For example you could use an Azure DevOps *build* pipeline to trigger an Azure ML pipeline that trains and registers a model, and when the model is registered it could trigger an Azure Devops *release* pipeline that deploys the model as a web service, along with the application or service that consumes the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
